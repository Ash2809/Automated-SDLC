{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9dcc3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\a\\envs\\env2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, END\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from typing import Any, Dict, List, Optional, Literal, TypedDict\n",
    "from dataclasses import dataclass, asdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c78517",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\", \n",
    "    api_key=GOOGLE_API_KEY,\n",
    "    temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "056c0a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, world!\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello, world!\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19523bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Gemini:\n",
    "    def __init__(self):\n",
    "        self.model = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-1.5-flash\",\n",
    "            api_key=GOOGLE_API_KEY,\n",
    "            temperature=0.1\n",
    "        )\n",
    "\n",
    "    def complete(self, system: str, user: str, **kwargs) -> str:\n",
    "        messages = []\n",
    "        if system.strip():\n",
    "            messages.append({\"role\": \"system\", \"content\": system.strip()})\n",
    "        messages.append({\"role\": \"user\", \"content\": user.strip()})\n",
    "\n",
    "        resp = self.model.invoke(messages)\n",
    "        return resp.content if hasattr(resp, \"content\") else str(resp)\n",
    "\n",
    "\n",
    "LLM = Gemini()\n",
    "print(LLM.complete(system=\"\", user=\"Hello\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ecec32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Constraint:\n",
    "    tech_stack : Optional[str] = None\n",
    "    deployment : Optional[str]= None\n",
    "    priority : Optional[Literal[\"high\", \"medium\", \"low\"]] = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64fe09f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ProjectSpec:\n",
    "    project_name : str\n",
    "    description : str\n",
    "    features : List[str]\n",
    "    constraints : Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92836620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrchestratorState(TypedDict, total = False):\n",
    "    spec = Dict[str, Any]\n",
    "\n",
    "    #Artifacts \n",
    "    user_stories: List[Dict[str, Any]]\n",
    "    architecture : Dict[str, Any]\n",
    "    plan : List[Dict[str, Any]]\n",
    "    code_changes : Dict[str, str]\n",
    "    tests : Dict[str, str]\n",
    "    test_report : Dict[str, str]\n",
    "    ci_cd : Dict[str, str]\n",
    "    deployment : Dict[str, str]\n",
    "\n",
    "    #these are for logging each nde in langgraph\n",
    "    approvals : Dict[str, Any]\n",
    "    repo_url : Optional[str]\n",
    "    run_id : Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ea02b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HitlProvider:\n",
    "    def request(self, gate: str, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class CLIHitl(HitlProvider):\n",
    "    def request(self, gate: str, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        print(\"\\n===== HITL GATE:\", gate, \"=====\")\n",
    "\n",
    "        print(json.dumps(payload, indent=2)[:4000])\n",
    "\n",
    "        while True:\n",
    "            ans = input(\"Approve? [y/n/e=edit]: \").strip().lower()\n",
    "            if ans in {\"y\", \"n\", \"e\"}:\n",
    "                break\n",
    "\n",
    "        notes = \"\"\n",
    "\n",
    "        if ans == \"e\":\n",
    "            print(\"Enter revised JSON (end with an empty line):\")\n",
    "            buf = []\n",
    "            while True:\n",
    "                line = input()\n",
    "                if not line:\n",
    "                    break\n",
    "                buf.append(line)\n",
    "            try:\n",
    "                revised = json.loads(\"\\n\".join(buf))\n",
    "                payload = revised\n",
    "            except Exception as e:\n",
    "                print(\"Invalid JSON, keeping original:\", e)\n",
    "        \n",
    "        elif ans == \"n\":\n",
    "            notes = input(\"Reason for rejection? \")\n",
    "        \n",
    "        return {\"approved\": ans == \"y\", \"payload\": payload, \"notes\": notes, \"by\": \"cli-user\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49d47b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "hitl_provider : HitlProvider = CLIHitl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34ab5183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_spec(raw : Dict[str, Any]) -> ProjectSpec:\n",
    "    constraints = raw.get(\"constraints\") or {}\n",
    "    return ProjectSpec(\n",
    "        project_name = raw.get(\"project_name\", \"Untitled Project\"),\n",
    "        description = raw.get(\"description\", \"\"),\n",
    "        features = raw.get(\"features\", []),\n",
    "        constraints= Constraint(\n",
    "            tech_stack = constraints.get(\"tech_stack\"),\n",
    "            deployment = constraints.get(\"deployment\"),\n",
    "            priority = constraints.get(\"priority\")\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73bba564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_json(data : Any) -> str:\n",
    "    return json.dumps(data, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3225d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_json(text: str):\n",
    "    match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group())\n",
    "        except json.JSONDecodeError:\n",
    "            return {}\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3367811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def requirements_node(state : OrchestratorState) -> OrchestratorState:\n",
    "#     spec = normalize_spec(state[\"spec\"])\n",
    "#     prompt_sys = (\n",
    "#         \"You are a senior product manager. Convert the input spec into precise, testable user stories. \"\n",
    "#         \"Use INVEST. Include acceptance criteria and non-functional requirements when relevant.\"\n",
    "#     )\n",
    "\n",
    "#     prompt_user = f\"SPEC:\\n{to_json(asdict(spec))}\\nReturn json with fields: user_stories[].\"\n",
    "    \n",
    "#     text = LLM.complete(system=prompt_sys, user=prompt_user)\n",
    "#     print(\"LLM response:\", text[:4000])\n",
    "\n",
    "#     try:\n",
    "#         data = json.loads(text)\n",
    "#         stories = data.get(\"user_stories\", [])\n",
    "#     except Exception:\n",
    "#         stories = []\n",
    "#     return {**state, \"user_stories\": stories}\n",
    "    \n",
    "def requirements_node(state: OrchestratorState) -> OrchestratorState:\n",
    "    spec = normalize_spec(state[\"spec\"])\n",
    "    prompt_sys = (\n",
    "        \"You are a senior product manager. Convert the input spec into precise, testable user stories. \"\n",
    "        \"Use INVEST. Include acceptance criteria and non-functional requirements when relevant.\"\n",
    "    )\n",
    "    prompt_user = f\"SPEC:\\n{to_json(asdict(spec))}\\nReturn JSON with fields: user_stories[].\"\n",
    "\n",
    "    text = LLM.complete(system=prompt_sys, user=prompt_user)\n",
    "    # print(\"LLM response (truncated):\", text[:1000])\n",
    "\n",
    "    # Extract the first valid JSON object\n",
    "    data = extract_json(text)\n",
    "    stories = data.get(\"user_stories\", [])\n",
    "    return {**state, \"user_stories\": stories}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2a68812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"spec\": {\n",
      "    \"project_name\": \"Task Manager\",\n",
      "    \"description\": \"A simple task management app\",\n",
      "    \"features\": [\n",
      "      \"add task\",\n",
      "      \"list tasks\",\n",
      "      \"mark task done\"\n",
      "    ],\n",
      "    \"constraints\": {\n",
      "      \"tech_stack\": \"Python + FastAPI\"\n",
      "    }\n",
      "  },\n",
      "  \"user_stories\": [\n",
      "    {\n",
      "      \"id\": \"US001\",\n",
      "      \"title\": \"As a user, I want to add a new task to the task manager so that I can keep track of my to-dos.\",\n",
      "      \"description\": \"Allows users to add tasks with a description and optional due date.\",\n",
      "      \"acceptance_criteria\": [\n",
      "        \"The system shall allow users to input a task description (text field, minimum 1 character).\",\n",
      "        \"The system shall allow users to optionally input a due date (date picker).\",\n",
      "        \"The system shall display a success message upon successful task creation.\",\n",
      "        \"The system shall handle invalid input (e.g., empty description) gracefully with appropriate error messages.\",\n",
      "        \"The newly added task should be immediately visible in the task list.\"\n",
      "      ],\n",
      "      \"priority\": \"High\",\n",
      "      \"estimated_effort\": \"3 days\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"US002\",\n",
      "      \"title\": \"As a user, I want to see a list of all my tasks so that I can review my to-dos.\",\n",
      "      \"description\": \"Displays a list of all tasks, including their description and due date (if any).\",\n",
      "      \"acceptance_criteria\": [\n",
      "        \"The system shall display a list of all tasks added by the user.\",\n",
      "        \"Each task in the list shall display its description.\",\n",
      "        \"Each task in the list shall display its due date (if set).\",\n",
      "        \"The list shall be sortable by due date (ascending and descending).\",\n",
      "        \"The list shall be paginated if the number of tasks exceeds a predefined limit (e.g., 20 tasks per page).\"\n",
      "      ],\n",
      "      \"priority\": \"High\",\n",
      "      \"estimated_effort\": \"2 days\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"US003\",\n",
      "      \"title\": \"As a user, I want to mark a task as done so that I can track my progress.\",\n",
      "      \"description\": \"Allows users to mark a task as complete.\",\n",
      "      \"acceptance_criteria\": [\n",
      "        \"The system shall provide a mechanism (e.g., checkbox) to mark a task as complete.\",\n",
      "        \"Upon marking a task as complete, its status should be updated accordingly.\",\n",
      "        \"Completed tasks should be visually distinct from incomplete tasks (e.g., strikethrough, different color).\",\n",
      "        \"The system should prevent marking a task as done if it's already done.\"\n",
      "      ],\n",
      "      \"priority\": \"High\",\n",
      "      \"estimated_effort\": \"1 day\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sample_state = {\n",
    "        \"spec\": {\n",
    "            \"project_name\": \"Task Manager\",\n",
    "            \"description\": \"A simple task management app\",\n",
    "            \"features\": [\"add task\", \"list tasks\", \"mark task done\"],\n",
    "            \"constraints\": {\"tech_stack\": \"Python + FastAPI\"}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    result = requirements_node(sample_state)\n",
    "    print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba99e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
